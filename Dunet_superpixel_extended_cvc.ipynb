{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:05:13.717979567Z",
     "start_time": "2023-10-31T22:05:09.288353987Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 23:05:10.476529: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-31 23:05:10.726094: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-31 23:05:11.915943: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/somayeh/PycharmProjects/superpixel_segmentation/venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-10-31 23:05:11.916224: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/somayeh/PycharmProjects/superpixel_segmentation/venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-10-31 23:05:11.916233: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import tifffile as tif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.segmentation import slic, mark_boundaries\n",
    "from skimage.color import label2rgb, rgb2gray\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "import glob\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "from cv2 import imread, createCLAHE\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras import backend as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from IPython.display import clear_output\n",
    "from keras.optimizers import Adamax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.morphology import binary_erosion, disk\n",
    "import keras.backend as K\n",
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed\n",
    "from skimage.filters import sobel\n",
    "from tqdm import tqdm\n",
    "from keras.losses import Loss\n",
    "from keras.callbacks import TensorBoard\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16, VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:01.799571932Z",
     "start_time": "2023-10-31T22:06:01.671192149Z"
    }
   },
   "id": "eb8dcd23893e77df"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    PadIfNeeded,\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,\n",
    "    CenterCrop,\n",
    "    Crop,\n",
    "    Compose,\n",
    "    Transpose,\n",
    "    RandomRotate90,\n",
    "    ElasticTransform,\n",
    "    GridDistortion,\n",
    "    OpticalDistortion,\n",
    "    RandomSizedCrop,\n",
    "    OneOf,\n",
    "    CLAHE,\n",
    "    RandomBrightnessContrast,\n",
    "    RandomGamma,\n",
    "    HueSaturationValue,\n",
    "    RGBShift,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    GaussNoise,\n",
    "    ChannelShuffle,\n",
    "    CoarseDropout\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:04.271786301Z",
     "start_time": "2023-10-31T22:06:04.109678289Z"
    }
   },
   "id": "9e94b3310fb47235"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def read_data(x, y):\n",
    "    \"\"\" Read the image and mask from the given path. \"\"\"\n",
    "    image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "    mask = cv2.imread(y, cv2.IMREAD_COLOR)\n",
    "    return image, mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:05.425621751Z",
     "start_time": "2023-10-31T22:06:05.388844363Z"
    }
   },
   "id": "a216076571a04fde"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def augment_data(images, masks, save_path, augment=True):\n",
    "    \"\"\" Performing data augmentation. \"\"\"\n",
    "    crop_size = (192-32, 256-32)\n",
    "    size = (256, 192)\n",
    "\n",
    "    for image, mask in tqdm(zip(images, masks), total=len(images)):\n",
    "        image_name = image.split(\"/\")[-1].split(\".\")[0]\n",
    "        mask_name = mask.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        x, y = read_data(image, mask)\n",
    "        try:\n",
    "            h, w, c = x.shape\n",
    "        except Exception as e:\n",
    "            image = image[:-1]\n",
    "            x, y = read_data(image, mask)\n",
    "            h, w, c = x.shape\n",
    "\n",
    "        if augment == True:\n",
    "            ## Center Crop\n",
    "            aug = CenterCrop(p=1, height=crop_size[0], width=crop_size[1])\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x1 = augmented['image']\n",
    "            y1 = augmented['mask']\n",
    "\n",
    "            ## Crop\n",
    "            x_min = 0\n",
    "            y_min = 0\n",
    "            x_max = x_min + size[0]\n",
    "            y_max = y_min + size[1]\n",
    "\n",
    "            aug = Crop(p=1, x_min=x_min, x_max=x_max, y_min=y_min, y_max=y_max)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x2 = augmented['image']\n",
    "            y2 = augmented['mask']\n",
    "\n",
    "            ## Random Rotate 90 degree\n",
    "            aug = RandomRotate90(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x3 = augmented['image']\n",
    "            y3 = augmented['mask']\n",
    "\n",
    "            ## Transpose\n",
    "            aug = Transpose(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x4 = augmented['image']\n",
    "            y4 = augmented['mask']\n",
    "\n",
    "            ## ElasticTransform\n",
    "            aug = ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x5 = augmented['image']\n",
    "            y5 = augmented['mask']\n",
    "\n",
    "            ## Grid Distortion\n",
    "            aug = GridDistortion(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x6 = augmented['image']\n",
    "            y6 = augmented['mask']\n",
    "\n",
    "            ## Optical Distortion\n",
    "            aug = OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x7 = augmented['image']\n",
    "            y7 = augmented['mask']\n",
    "\n",
    "            ## Vertical Flip\n",
    "            aug = VerticalFlip(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x8 = augmented['image']\n",
    "            y8 = augmented['mask']\n",
    "\n",
    "            ## Horizontal Flip\n",
    "            aug = HorizontalFlip(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x9 = augmented['image']\n",
    "            y9 = augmented['mask']\n",
    "\n",
    "            ## Grayscale\n",
    "            x10 = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY)\n",
    "            y10 = y\n",
    "\n",
    "            ## Grayscale Vertical Flip\n",
    "            aug = VerticalFlip(p=1)\n",
    "            augmented = aug(image=x10, mask=y10)\n",
    "            x11 = augmented['image']\n",
    "            y11 = augmented['mask']\n",
    "\n",
    "            ## Grayscale Horizontal Flip\n",
    "            aug = HorizontalFlip(p=1)\n",
    "            augmented = aug(image=x10, mask=y10)\n",
    "            x12 = augmented['image']\n",
    "            y12 = augmented['mask']\n",
    "\n",
    "            ## Grayscale Center Crop\n",
    "            aug = CenterCrop(p=1, height=crop_size[0], width=crop_size[1])\n",
    "            augmented = aug(image=x10, mask=y10)\n",
    "            x13 = augmented['image']\n",
    "            y13 = augmented['mask']\n",
    "\n",
    "            ##\n",
    "            aug = RandomBrightnessContrast(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x14 = augmented['image']\n",
    "            y14 = augmented['mask']\n",
    "\n",
    "            aug = RandomGamma(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x15 = augmented['image']\n",
    "            y15 = augmented['mask']\n",
    "\n",
    "            aug = HueSaturationValue(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x16 = augmented['image']\n",
    "            y16 = augmented['mask']\n",
    "\n",
    "            aug = RGBShift(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x17 = augmented['image']\n",
    "            y17 = augmented['mask']\n",
    "\n",
    "            aug = RandomBrightness(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x18 = augmented['image']\n",
    "            y18 = augmented['mask']\n",
    "\n",
    "            aug = RandomContrast(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x19 = augmented['image']\n",
    "            y19 = augmented['mask']\n",
    "\n",
    "            aug = MotionBlur(p=1, blur_limit=7)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x20 = augmented['image']\n",
    "            y20 = augmented['mask']\n",
    "\n",
    "            aug = MedianBlur(p=1, blur_limit=(3, 9))\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x21 = augmented['image']\n",
    "            y21 = augmented['mask']\n",
    "\n",
    "\n",
    "            aug = GaussianBlur(p=1, blur_limit=(3, 9))\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x22 = augmented['image']\n",
    "            y22 = augmented['mask']\n",
    "\n",
    "            aug = GaussNoise(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x23 = augmented['image']\n",
    "            y23 = augmented['mask']\n",
    "\n",
    "            aug = ChannelShuffle(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x24 = augmented['image']\n",
    "            y24 = augmented['mask']\n",
    "\n",
    "            aug = CoarseDropout(p=1, max_holes=8, max_height=32, max_width=32)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x25 = augmented['image']\n",
    "            y25 = augmented['mask']\n",
    "\n",
    "            images = [\n",
    "                x, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10,\n",
    "                x11, x12, x13, x14, x15, x16, x17, x18, x19, x20,\n",
    "                x21, x22, x23, x24, x25\n",
    "            ]\n",
    "            masks  = [\n",
    "                y, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10,\n",
    "                y11, y12, y13, y14, y15, y16, y17, y18, y19, y20,\n",
    "                y21, y22, y23, y24, y25\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            images = [x]\n",
    "            masks  = [y]\n",
    "\n",
    "        idx = 0\n",
    "        for i, m in zip(images, masks):\n",
    "            i = cv2.resize(i, size)\n",
    "            m = cv2.resize(m, size)\n",
    "\n",
    "            tmp_image_name = f\"{image_name}_{idx}.jpg\"\n",
    "            tmp_mask_name  = f\"{mask_name}_{idx}.jpg\"\n",
    "\n",
    "            image_path = os.path.join(save_path, \"image/\", tmp_image_name)\n",
    "            mask_path  = os.path.join(save_path, \"mask/\", tmp_mask_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "            cv2.imwrite(mask_path, m)\n",
    "\n",
    "            idx += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:06.213048016Z",
     "start_time": "2023-10-31T22:06:06.185800090Z"
    }
   },
   "id": "8aabeab6df0c0a48"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_skin_lesion_data(path, split=0.1):\n",
    "    train_x = glob(os.path.join(path, \"../cvc-clinic/trainx/*.png\"))\n",
    "    train_y = glob(os.path.join(path, \"../cvc-clinic/trainy/*.png\"))\n",
    "\n",
    "    valid_x = glob(os.path.join(path, \"../cvc-clinic/validationx/*.png\"))\n",
    "    valid_y = glob(os.path.join(path, \"../cvc-clinic/validationy/*.png\"))\n",
    "\n",
    "    test_x = glob(os.path.join(path, \"cvc-clinic/testx/*.png\"))\n",
    "    test_y = glob(os.path.join(path, \"cvc-clinic/testy/*.png\"))\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:07.396901080Z",
     "start_time": "2023-10-31T22:06:07.366442635Z"
    }
   },
   "id": "1e81567f5961361b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    \"\"\" Create a directory. \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "    except OSError:\n",
    "        print(f\"Error: creating directory with name {path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:08.542872466Z",
     "start_time": "2023-10-31T22:06:08.521264878Z"
    }
   },
   "id": "bf1214d9534d77b8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mseed(\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m      2\u001B[0m path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/home/somayeh/PycharmProjects/superpixel_segmentation/cvc-clinic\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 3\u001B[0m (train_x, train_y), (valid_x, valid_y), (test_x, test_y) \u001B[38;5;241m=\u001B[39m \u001B[43mget_skin_lesion_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m create_dir(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnew_data/train/image/\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m create_dir(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnew_data/train/mask/\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m, in \u001B[0;36mget_skin_lesion_data\u001B[0;34m(path, split)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_skin_lesion_data\u001B[39m(path, split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m):\n\u001B[0;32m----> 2\u001B[0m     train_x \u001B[38;5;241m=\u001B[39m \u001B[43mglob\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../cvc-clinic/trainx/*.png\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     train_y \u001B[38;5;241m=\u001B[39m glob(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../cvc-clinic/trainy/*.png\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m      5\u001B[0m     valid_x \u001B[38;5;241m=\u001B[39m glob(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../cvc-clinic/validationx/*.png\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "\u001B[0;31mTypeError\u001B[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "path = \"/home/somayeh/PycharmProjects/superpixel_segmentation/cvc-clinic\"\n",
    "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = get_skin_lesion_data(path, split=0.1)\n",
    "\n",
    "create_dir(\"new_data/train/image/\")\n",
    "create_dir(\"new_data/train/mask/\")\n",
    "create_dir(\"new_data/valid/image/\")\n",
    "create_dir(\"new_data/valid/mask/\")\n",
    "create_dir(\"new_data/test/image/\")\n",
    "create_dir(\"new_data/test/mask/\")\n",
    "\n",
    "augment_data(train_x, train_y, \"new_data/train/\", augment=True)\n",
    "augment_data(valid_x, valid_y, \"new_data/valid/\", augment=False)\n",
    "augment_data(test_x, test_y, \"new_data/test/\", augment=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:12.199568969Z",
     "start_time": "2023-10-31T22:06:11.632589386Z"
    }
   },
   "id": "aad28011fead5418"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "image_paths=glob.glob( \"/home/somayeh/PycharmProjects/superpixel_segmentation/new_data/train/image/*.jpg\")\n",
    "mask_paths =glob.glob( \"/home/somayeh/PycharmProjects/superpixel_segmentation/new_data/train/mask/*.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:20.970103343Z",
     "start_time": "2023-10-31T22:06:20.816533191Z"
    }
   },
   "id": "fe9d9ad2199c7da6"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 17\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m image_path \u001B[38;5;129;01min\u001B[39;00m image_paths:\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;66;03m# Generate the output path for the resized image\u001B[39;00m\n\u001B[1;32m     16\u001B[0m     output_path \u001B[38;5;241m=\u001B[39m image_path\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresized_image\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 17\u001B[0m     \u001B[43mresize_and_save\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Repeat the same process for mask images\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mask_path \u001B[38;5;129;01min\u001B[39;00m mask_paths:\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;66;03m# Generate the output path for the resized mask\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[10], line 8\u001B[0m, in \u001B[0;36mresize_and_save\u001B[0;34m(image_path, output_path)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mresize_and_save\u001B[39m(image_path, output_path):\n\u001B[0;32m----> 8\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m image \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     10\u001B[0m         resized_image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mresize(image, target_size)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "target_size = (128, 128)\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(\"/home/somayeh/PycharmProjects/superpixel_segmentation/new_data/train/resized_image\", exist_ok=True)\n",
    "os.makedirs(\"/home/somayeh/PycharmProjects/superpixel_segmentation/new_data/train/resized_mask\", exist_ok=True)\n",
    "\n",
    "# Function to resize and save an image\n",
    "def resize_and_save(image_path, output_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is not None:\n",
    "        resized_image = cv2.resize(image, target_size)\n",
    "        cv2.imwrite(output_path, resized_image)\n",
    "\n",
    "# Process and resize the images\n",
    "for image_path in image_paths:\n",
    "    # Generate the output path for the resized image\n",
    "    output_path = image_path.replace(\"image\", \"resized_image\")\n",
    "    resize_and_save(image_path, output_path)\n",
    "\n",
    "# Repeat the same process for mask images\n",
    "for mask_path in mask_paths:\n",
    "    # Generate the output path for the resized mask\n",
    "    output_path = mask_path.replace(\"mask\", \"resized_mask\")\n",
    "    resize_and_save(mask_path, output_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:42.386024424Z",
     "start_time": "2023-10-31T22:06:25.046858789Z"
    }
   },
   "id": "6e2a2f4067a26543"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# initialize empty arrays to hold the images and masks\n",
    "images = []\n",
    "masks = []\n",
    "images_superpixel = []\n",
    "binary_masks = []\n",
    "masks_superpixel = []\n",
    "masks_result = []\n",
    "binary = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:46.061945763Z",
     "start_time": "2023-10-31T22:06:45.977818776Z"
    }
   },
   "id": "9ae3f91f725c6934"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def ground_truth_superpixel_1(img, ground_truth):\n",
    "    # Perform superpixel segmentation\n",
    "    num_segments = 800\n",
    "    segments = slic(img, n_segments=num_segments, compactness=10)\n",
    "\n",
    "\n",
    "    image_superpixel = label2rgb(segments, img, kind='avg')\n",
    "    image_superpixel = rgb2gray(image_superpixel)\n",
    "    num_superpixels = len(np.unique(segments))\n",
    "    # print(f'The image contains {num_superpixels} superpixels.')\n",
    "\n",
    "    image_boundaries = mark_boundaries(img, segments, color=(255, 0, 0))\n",
    "    labels = segments.astype(np.int32)\n",
    "\n",
    "    # Overlay superpixels with ground truth\n",
    "    inside_mask = (ground_truth == 255)  # white pixels in ground truth are inside the chest region\n",
    "    outside_mask = (ground_truth == 0)  # black pixels in ground truth are outside the chest region\n",
    "    boundary_mask = cv2.morphologyEx(ground_truth, cv2.MORPH_GRADIENT, np.ones((5, 5), np.uint8)) > 0\n",
    "\n",
    "    inside_superpixels = set(np.unique(labels[inside_mask]))\n",
    "    outside_superpixels = set(np.unique(labels[outside_mask]))\n",
    "    boundary_superpixels = set(np.unique(labels[boundary_mask]))\n",
    "\n",
    "    # Exclude boundary superpixels\n",
    "    valid_superpixels = list(outside_superpixels.union(inside_superpixels) - boundary_superpixels)\n",
    "\n",
    "    for label in boundary_superpixels:\n",
    "        mask = (labels == label)\n",
    "        # Check if the superpixel intersects with the boundary\n",
    "        if np.any(mask[0, :]) or np.any(mask[-1, :]) or np.any(mask[:, 0]) or np.any(mask[:, -1]):\n",
    "            boundary_mask_ = binary_erosion(boundary_mask,\n",
    "                                            disk(\n",
    "                                                3))  # erode the boundary mask to avoid including partial boundary pixels\n",
    "            valid_superpixels = list(outside_superpixels.union(inside_superpixels) - set(labels[boundary_mask_]))\n",
    "\n",
    "    num_segments_result = len(np.unique(valid_superpixels))\n",
    "    # print(f'The result image contains {num_segments_result} superpixels.')\n",
    "\n",
    "    # Assign labels and color superpixels\n",
    "    result = np.zeros_like(img)\n",
    "    inside_labels = []\n",
    "    outside_labels = []\n",
    "    for label in valid_superpixels:\n",
    "        mask = (labels == label)\n",
    "        if label in inside_superpixels:\n",
    "            color = (255, 255, 255)  # yellow for inside superpixels\n",
    "            inside_labels.append(label)\n",
    "        else:\n",
    "            color = (0, 0, 0)  # blue for outside superpixels\n",
    "            outside_labels.append(label)\n",
    "        result[mask] = color\n",
    "\n",
    "    # Set background class for the omitted superpixels\n",
    "    background_mask = (ground_truth == 0)\n",
    "    result[background_mask] = (0, 0, 0)\n",
    "\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:50.267565915Z",
     "start_time": "2023-10-31T22:06:50.207258846Z"
    }
   },
   "id": "8228973fd546c1c2"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def ground_truth_superpixel_3(img, ground_truth):\n",
    "    # Perform SLIC superpixel segmentation\n",
    "    num_segments = 800\n",
    "    segments = slic(img, n_segments=num_segments, compactness=10)\n",
    "    # segments = felzenszwalb(img, scale=20, sigma=0.5, min_size=30)\n",
    "    # segments = quickshift(img, kernel_size=1, max_dist=2.5, ratio=0.5)\n",
    "\n",
    "    # Find superpixels intersecting with the image boundaries\n",
    "    boundary_mask = cv2.morphologyEx(ground_truth, cv2.MORPH_GRADIENT, np.ones((5, 5), np.uint8)) > 0\n",
    "    boundary_superpixels = set(segments[boundary_mask])\n",
    "\n",
    "    # Show the number of superpixels with intersection with image boundaries\n",
    "    num_boundary_superpixels = len(boundary_superpixels)\n",
    "    # print(f'The number of superpixels with intersection with image boundaries: {num_boundary_superpixels}')\n",
    "\n",
    "    # Overlay superpixels with ground truth\n",
    "    labels = segments.astype(np.int32)\n",
    "\n",
    "    inside_mask = (ground_truth == 255)  # white pixels in ground truth are inside the chest region\n",
    "    outside_mask = (ground_truth == 0)  # black pixels in ground truth are outside the chest region\n",
    "\n",
    "    inside_superpixels = set(np.unique(labels[inside_mask]))\n",
    "    outside_superpixels = set(np.unique(labels[outside_mask]))\n",
    "\n",
    "    # Assign labels and color superpixels\n",
    "    result = np.zeros_like(img)\n",
    "    for label in outside_superpixels:\n",
    "        mask = (labels == label)\n",
    "        result[mask] = (0, 0, 0)  # Set label 0 (black) for superpixels outside the boundary\n",
    "\n",
    "    for label in inside_superpixels:\n",
    "        mask = (labels == label)\n",
    "        result[mask] = (255, 255, 255)  # Set label 1 (white) for superpixels inside the boundary\n",
    "\n",
    "    for label in boundary_superpixels:\n",
    "        mask = (labels == label)\n",
    "        num_pixels_inside = np.sum(mask & inside_mask)\n",
    "        num_pixels_outside = np.sum(mask & outside_mask)\n",
    "\n",
    "        if num_pixels_outside > num_pixels_inside:\n",
    "            result[mask] = (0, 0, 0)  # Set label 0 (black) for superpixels with more pixels outside the boundary\n",
    "        elif num_pixels_outside < num_pixels_inside:\n",
    "            result[mask] = (255, 255, 255)  # Set label 1 (white) for superpixels with more pixels inside the boundary\n",
    "        else:\n",
    "            d1 = cv2.distanceTransform((mask & outside_mask).astype(np.uint8), cv2.DIST_L2, 5)\n",
    "            d2 = cv2.distanceTransform((mask & inside_mask).astype(np.uint8), cv2.DIST_L2, 5)\n",
    "\n",
    "            d1_sorted = np.sort(d1[mask & boundary_mask])\n",
    "            d2_sorted = np.sort(d2[mask & boundary_mask])\n",
    "\n",
    "            threshold_idx = len(d1_sorted) // 2\n",
    "            if np.sum(d1_sorted[:threshold_idx]) > np.sum(d1_sorted[threshold_idx:]):\n",
    "                result[mask] = (0, 0, 0)  # Set label 0 (black) for superpixels with larger distance to outside\n",
    "            else:\n",
    "                result[mask] = (255, 255, 255)  # Set label 1 (white) for superpixels with larger distance to inside\n",
    "\n",
    "    # cv2.imshow('Result', result)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:52.032650264Z",
     "start_time": "2023-10-31T22:06:51.980900858Z"
    }
   },
   "id": "8b2de7e9337ec01e"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
    "    iou_score = (intersection + smooth) / (union + smooth)\n",
    "    return iou_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:53.824380503Z",
     "start_time": "2023-10-31T22:06:53.771821019Z"
    }
   },
   "id": "7e9a153c41c29483"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    y_true_flat = K.flatten(y_true)\n",
    "    y_pred_flat = K.flatten(y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true_flat * y_pred_flat, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred_flat, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "\n",
    "    return precision"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:54.571435781Z",
     "start_time": "2023-10-31T22:06:54.513809596Z"
    }
   },
   "id": "b9f18f59d03f6065"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def sensitivity(gt_mask, pred_mask):\n",
    "    \"\"\"\n",
    "    Computes sensitivity (recall) of the predicted segmentation mask\n",
    "    given the ground truth mask.\n",
    "\n",
    "    Args:\n",
    "        gt_mask (np.array): binary ground truth segmentation mask.\n",
    "        pred_mask (np.array): binary predicted segmentation mask.\n",
    "\n",
    "    Returns:\n",
    "        float: sensitivity score.\n",
    "    \"\"\"\n",
    "    gt_mask_flat = K.flatten(gt_mask)\n",
    "    pred_mask_flat = K.flatten(pred_mask)\n",
    "\n",
    "    # compute true positive (TP) and false negative (FN) counts\n",
    "    TP = K.sum(gt_mask_flat * pred_mask_flat)\n",
    "    FN = K.sum(gt_mask_flat * (1 - pred_mask_flat))\n",
    "\n",
    "    # compute sensitivity (recall)\n",
    "    if TP + FN == 0:\n",
    "        sensitivity_score = 0.0\n",
    "    else:\n",
    "        sensitivity_score = TP / (TP + FN)\n",
    "\n",
    "    return sensitivity_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:55.829501434Z",
     "start_time": "2023-10-31T22:06:55.762109275Z"
    }
   },
   "id": "51f7e20106a977a7"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:57.789508051Z",
     "start_time": "2023-10-31T22:06:57.734680652Z"
    }
   },
   "id": "9f8fe9a0658575ea"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred,1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:06:59.571803669Z",
     "start_time": "2023-10-31T22:06:59.509119605Z"
    }
   },
   "id": "e6096247a11ce0b5"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "image_path_1 = glob.glob(\"/home/somayeh/PycharmProjects/superpixel_segmentation/new_data/train/resized_image/*.jpg\")\n",
    "mask_path_1 = glob.glob(\"/home/somayeh/PycharmProjects/superpixel_segmentation/new_data/train/resized_mask/*.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:07:01.510901869Z",
     "start_time": "2023-10-31T22:07:01.354832858Z"
    }
   },
   "id": "2f309faec0b1dab7"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "threshold_value = 128\n",
    "def data_generator(image_paths, mask_paths, batch_size):\n",
    "\n",
    "    assert len(image_paths) == len(mask_paths), \"Number of images and masks must be the same.\"\n",
    "\n",
    "    num_samples = len(image_paths)\n",
    "    print(\"Number of images:\", num_samples)\n",
    "    num_masks = len(mask_paths)\n",
    "    print(\"Number of masks:\", num_masks)\n",
    "\n",
    "    while True:\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_indices = indices[i : i + batch_size]\n",
    "            batch_images = []\n",
    "            batch_masks = []\n",
    "\n",
    "            for index in batch_indices:\n",
    "                image_path = image_paths[index]\n",
    "                mask_path = mask_paths[index]\n",
    "\n",
    "                img = cv2.imread(image_path)\n",
    "                # img = cv2.resize(img, (256, 256))\n",
    "\n",
    "                filename = os.path.join(\"/home/somayeh/PycharmProjects/superpixel_segmentation/\"\n",
    "                                        \"newgt/newgt_superpixel_extended_128_CVC_slic800\", os.path.basename(mask_path))\n",
    "                if not os.path.exists(filename):\n",
    "\n",
    "                    mask = cv2.imread(mask_path,0)\n",
    "                    # mask = cv2.resize(mask, (256, 256))\n",
    "\n",
    "                    # result = ground_truth_superpixel_1(img, mask)\n",
    "                    result = ground_truth_superpixel_3(img, mask)\n",
    "\n",
    "                    # result = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
    "                    # plt.subplot(1, 2, 2)\n",
    "                    # plt.imshow(result)\n",
    "                    # plt.title(\"hggh\")\n",
    "\n",
    "                    # soft_label = binary_to_soft_label(result, threshold_value=threshold_value)\n",
    "                    # cv2.imshow(\"kjkj\",soft_label)\n",
    "                    # cv2.waitKey(0)\n",
    "                    # result = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    cv2.imwrite(filename, result)\n",
    "\n",
    "                else:\n",
    "                    result = cv2.imread(filename, 0)\n",
    "                # print(result.type)\n",
    "                # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                # soft_label = binary_to_soft_label(result)\n",
    "\n",
    "                # normalize the image and mask to have values between 0 and 1\n",
    "                # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                img = img / 255.0\n",
    "                result= result/ 255.0\n",
    "                # result = result / 255.0\n",
    "                # print(soft_label.shape)\n",
    "                # cv2.imshow(\"dfg\", soft_label)\n",
    "                # cv2.waitKey(0)\n",
    "                # Append the preprocessed data to the respective lists\n",
    "\n",
    "                batch_images.append(img)\n",
    "                batch_masks.append(result)\n",
    "\n",
    "            # Yield the batch data\n",
    "            batch_images = np.array(batch_images)\n",
    "            batch_masks = np.array(batch_masks)\n",
    "\n",
    "            # Visualize the images and masks in the batch\n",
    "            # for j in range(batch_images.shape[0]):\n",
    "            #     plt.subplot(1, 2, 1)\n",
    "            #     plt.imshow(batch_images[j])\n",
    "            #     plt.title(\"Image\")\n",
    "            #\n",
    "            #     plt.subplot(1, 2, 2)\n",
    "            #     plt.imshow(batch_masks[j])\n",
    "            #     plt.title(\"Mask\")\n",
    "            #\n",
    "            #     plt.show()\n",
    "\n",
    "            yield batch_images, batch_masks\n",
    "#\n",
    "# generator = data_generator(image_path_1, mask_path_1, 1)\n",
    "# \n",
    "# for _,imgpath in tqdm(enumerate(image_paths)):\n",
    "#    batch = next(generator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:07:19.684517054Z",
     "start_time": "2023-10-31T22:07:19.621155281Z"
    }
   },
   "id": "ea52507f57b5ad5e"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Number of images and masks must be the same.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m mask_path_superpixel \u001B[38;5;241m=\u001B[39m glob\u001B[38;5;241m.\u001B[39mglob (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/home/somayeh/PycharmProjects/superpixel_segmentation/newgt/newgt_superpixel_extended_128_CVC_slic800/*.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(image_path_1) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(mask_path_superpixel), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of images and masks must be the same.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Split the data into training and validation sets\u001B[39;00m\n\u001B[1;32m      4\u001B[0m train_image_paths, val_image_paths, train_mask_paths, val_mask_paths \u001B[38;5;241m=\u001B[39m train_test_split(\n\u001B[1;32m      5\u001B[0m     image_path_1, mask_path_superpixel, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2023\u001B[39m\n\u001B[1;32m      6\u001B[0m )\n",
      "\u001B[0;31mAssertionError\u001B[0m: Number of images and masks must be the same."
     ]
    }
   ],
   "source": [
    "mask_path_superpixel = glob.glob (\"/home/somayeh/PycharmProjects/superpixel_segmentation/newgt/newgt_superpixel_extended_128_CVC_slic800/*.jpg\")\n",
    "assert len(image_path_1) == len(mask_path_superpixel), \"Number of images and masks must be the same.\"\n",
    "# Split the data into training and validation sets\n",
    "train_image_paths, val_image_paths, train_mask_paths, val_mask_paths = train_test_split(\n",
    "    image_path_1, mask_path_superpixel, test_size=0.2, random_state=2023\n",
    ")\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 8\n",
    "\n",
    "# Create separate generators for training and validation sets\n",
    "train_generator = data_generator(train_image_paths, train_mask_paths, batch_size)\n",
    "val_generator = data_generator(val_image_paths, val_mask_paths, batch_size)\n",
    "\n",
    "# batch_size = 5  # Number of batches to visualize\n",
    "\n",
    "# for _ in range(batch_size):\n",
    "#     batch = next(train_generator)\n",
    "\n",
    "# Determine the number of steps per epoch for training and validation\n",
    "train_steps_per_epoch = len(train_image_paths) // batch_size\n",
    "val_steps_per_epoch = len(val_image_paths) // batch_size\n",
    "\n",
    "print(train_steps_per_epoch)\n",
    "print(val_steps_per_epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:07:43.128047130Z",
     "start_time": "2023-10-31T22:07:43.003810406Z"
    }
   },
   "id": "2b272a876e2cd0c7"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def build_unet(input_size=(256,256,3)):\n",
    "\n",
    "    inputs  = Input(input_size)\n",
    "\n",
    "    conv1 = Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3,3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3,3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3,3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
    "\n",
    "    conv6 = Conv2D(1024, (3, 3), activation='relu', padding='same') (pool5)\n",
    "    conv6 = Conv2D(1024, (3, 3), activation = 'relu', padding='same')(conv6)\n",
    "    pool6 = MaxPooling2D(pool_size=(2, 2))(conv6)\n",
    "\n",
    "\n",
    "    up7 = layers.concatenate([Conv2DTranspose(512, (2,2), strides=(2,2), padding='same')(conv6), conv5], axis=3)\n",
    "\n",
    "\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "\n",
    "    up8 = layers.concatenate([Conv2DTranspose(256, (2,2), strides=(2,2), padding='same')(conv7), conv4], axis=3)\n",
    "\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = layers.concatenate([Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(conv8), conv3], axis=3)\n",
    "\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    up10 = layers.concatenate([Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(conv9), conv2], axis=3)\n",
    "\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same')(up10)\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv10)\n",
    "\n",
    "    up11 = layers.concatenate([Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(conv10), conv1], axis=3)\n",
    "\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same')(up11)\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv11)\n",
    "\n",
    "    conv12 = Conv2D(1, (1,1), activation='relu')(conv11)\n",
    "\n",
    "    return Model(inputs=[inputs], outputs=[conv12])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:08:00.307664439Z",
     "start_time": "2023-10-31T22:08:00.092594163Z"
    }
   },
   "id": "e4066dc49812344c"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def build_unet_pretrained (input_size=(256, 256, 3)):\n",
    "    # Load pre-trained VGG16 model without top layers\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=input_size))\n",
    "\n",
    "    # Encoder part (using VGG16 layers)\n",
    "    encoder = base_model.get_layer('block5_conv3').output\n",
    "\n",
    "    # Decoder part (U-Net)\n",
    "    up7 = UpSampling2D(size=(2, 2))(encoder)\n",
    "    up7 = Conv2D(512, (2, 2), activation='relu', padding='same')(up7)\n",
    "    up7 = concatenate([up7, base_model.get_layer('block4_conv3').output], axis=-1)\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up6 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    up6 = Conv2D(256, (2, 2), activation='relu', padding='same')(up6)\n",
    "    up6 = concatenate([up6, base_model.get_layer('block3_conv3').output], axis=-1)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up5 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    up5 = Conv2D(128, (2, 2), activation='relu', padding='same')(up5)\n",
    "    up5 = concatenate([up5, base_model.get_layer('block2_conv2').output], axis=-1)\n",
    "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(up5)\n",
    "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up4 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    up4 = Conv2D(64, (2, 2), activation='relu', padding='same')(up4)\n",
    "    up4 = concatenate([up4, base_model.get_layer('block1_conv2').output], axis=-1)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up4)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up3 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up3 = Conv2D(32, (2, 2), activation='relu', padding='same')(up3)\n",
    "\n",
    "    # Continue with the rest of your U-Net decoder as before\n",
    "\n",
    "    # Final convolutional layer\n",
    "    conv12 = Conv2D(1, (1, 1), activation='sigmoid')(up3)\n",
    "\n",
    "    return Model(inputs=[base_model.input], outputs=[conv12])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:08:01.317693408Z",
     "start_time": "2023-10-31T22:08:01.273619080Z"
    }
   },
   "id": "bf3778d7fe356667"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def squeeze_excite_block(inputs, ratio=8):\n",
    "    init = inputs\n",
    "    channel_axis = -1\n",
    "    filters = init.shape[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "\n",
    "    x = Multiply()([init, se])\n",
    "    return x\n",
    "\n",
    "def conv_block(inputs, filters):\n",
    "    x = inputs\n",
    "\n",
    "    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = squeeze_excite_block(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def encoder1(inputs):\n",
    "    skip_connections = []\n",
    "\n",
    "    model = VGG19(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "    names = [\"block1_conv2\", \"block2_conv2\", \"block3_conv4\", \"block4_conv4\"]\n",
    "    for name in names:\n",
    "        skip_connections.append(model.get_layer(name).output)\n",
    "\n",
    "    output = model.get_layer(\"block5_conv4\").output\n",
    "    return output, skip_connections\n",
    "\n",
    "def decoder1(inputs, skip_connections):\n",
    "    num_filters = [256, 128, 64, 32]\n",
    "    skip_connections.reverse()\n",
    "    x = inputs\n",
    "\n",
    "    for i, f in enumerate(num_filters):\n",
    "        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\n",
    "        x = Concatenate()([x, skip_connections[i]])\n",
    "        x = conv_block(x, f)\n",
    "\n",
    "    return x\n",
    "\n",
    "# def encoder2(inputs):\n",
    "#     skip_connections = []\n",
    "#\n",
    "#     output = DenseNet121(include_top=False, weights='imagenet')(inputs)\n",
    "#     model = tf.keras.models.Model(inputs, output)\n",
    "#\n",
    "#     names = [\"input_2\", \"conv1/relu\", \"pool2_conv\", \"pool3_conv\"]\n",
    "#     for name in names:\n",
    "#         skip_connections.append(model.get_layer(name).output)\n",
    "#     output = model.get_layer(\"pool4_conv\").output\n",
    "#\n",
    "#     return output, skip_connections\n",
    "\n",
    "def encoder2(inputs):\n",
    "    num_filters = [32, 64, 128, 256]\n",
    "    skip_connections = []\n",
    "    x = inputs\n",
    "\n",
    "    for i, f in enumerate(num_filters):\n",
    "        x = conv_block(x, f)\n",
    "        skip_connections.append(x)\n",
    "        x = MaxPool2D((2, 2))(x)\n",
    "\n",
    "    return x, skip_connections\n",
    "\n",
    "def decoder2(inputs, skip_1, skip_2):\n",
    "    num_filters = [256, 128, 64, 32]\n",
    "    skip_2.reverse()\n",
    "    x = inputs\n",
    "\n",
    "    for i, f in enumerate(num_filters):\n",
    "        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\n",
    "        x = Concatenate()([x, skip_1[i], skip_2[i]])\n",
    "        x = conv_block(x, f)\n",
    "\n",
    "    return x\n",
    "\n",
    "def output_block(inputs):\n",
    "    x = Conv2D(1, (1, 1), padding=\"same\")(inputs)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    return x\n",
    "\n",
    "def Upsample(tensor, size):\n",
    "    \"\"\"Bilinear upsampling\"\"\"\n",
    "    def _upsample(x, size):\n",
    "        return tf.image.resize(images=x, size=size)\n",
    "    return Lambda(lambda x: _upsample(x, size), output_shape=size)(tensor)\n",
    "\n",
    "def ASPP(x, filter):\n",
    "    shape = x.shape\n",
    "\n",
    "    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(x)\n",
    "    y1 = Conv2D(filter, 1, padding=\"same\")(y1)\n",
    "    y1 = BatchNormalization()(y1)\n",
    "    y1 = Activation(\"relu\")(y1)\n",
    "    y1 = UpSampling2D((shape[1], shape[2]), interpolation='bilinear')(y1)\n",
    "\n",
    "    y2 = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(x)\n",
    "    y2 = BatchNormalization()(y2)\n",
    "    y2 = Activation(\"relu\")(y2)\n",
    "\n",
    "    y3 = Conv2D(filter, 3, dilation_rate=6, padding=\"same\", use_bias=False)(x)\n",
    "    y3 = BatchNormalization()(y3)\n",
    "    y3 = Activation(\"relu\")(y3)\n",
    "\n",
    "    y4 = Conv2D(filter, 3, dilation_rate=12, padding=\"same\", use_bias=False)(x)\n",
    "    y4 = BatchNormalization()(y4)\n",
    "    y4 = Activation(\"relu\")(y4)\n",
    "\n",
    "    y5 = Conv2D(filter, 3, dilation_rate=18, padding=\"same\", use_bias=False)(x)\n",
    "    y5 = BatchNormalization()(y5)\n",
    "    y5 = Activation(\"relu\")(y5)\n",
    "\n",
    "    y = Concatenate()([y1, y2, y3, y4, y5])\n",
    "\n",
    "    y = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "\n",
    "    return y\n",
    "\n",
    "def build_model(shape):\n",
    "    inputs = Input(shape)\n",
    "    x, skip_1 = encoder1(inputs)\n",
    "    x = ASPP(x, 64)\n",
    "    x = decoder1(x, skip_1)\n",
    "    outputs1 = output_block(x)\n",
    "\n",
    "    x = inputs * outputs1\n",
    "\n",
    "    x, skip_2 = encoder2(x)\n",
    "    x = ASPP(x, 64)\n",
    "    x = decoder2(x, skip_1, skip_2)\n",
    "    outputs2 = output_block(x)\n",
    "    # outputs = Concatenate()([outputs1, outputs2])\n",
    "\n",
    "    model = Model(inputs, outputs2)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:08:02.990156324Z",
     "start_time": "2023-10-31T22:08:02.921506726Z"
    }
   },
   "id": "f21c4e0a7d41fb14"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "!rm -rf '/home/somayeh/PycharmProjects/superpixel_segmentation/tensor_board'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:08:04.869617021Z",
     "start_time": "2023-10-31T22:08:04.567026350Z"
    }
   },
   "id": "3a3eb65b56e1c56f"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "log_folder = '/home/somayeh/PycharmProjects/superpixel_segmentation/tensor_board'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:08:05.730816023Z",
     "start_time": "2023-10-31T22:08:05.673038213Z"
    }
   },
   "id": "a9b7002756e31ea1"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 23:08:06.523433: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2023-10-31 23:08:06.523514: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2023-10-31 23:08:06.574257: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1664] Profiler found 1 GPUs\n",
      "2023-10-31 23:08:06.575101: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/somayeh/PycharmProjects/superpixel_segmentation/venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-10-31 23:08:06.637366: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2023-10-31 23:08:06.637872: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "weight_path=\"{}_Dunet_superpixel_extended_cvc_slic800.best.hdf5\".format('cxr_reg')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                   patience=3,\n",
    "                                   verbose=1, mode='min', epsilon=0.0001, cooldown=2, min_lr=1e-5)\n",
    "early = EarlyStopping(monitor=\"val_loss\",\n",
    "                      mode=\"min\",\n",
    "                      patience=10) # probably needs to be more patient, but kaggle time is limited\n",
    "\n",
    "tbcallback = TensorBoard(log_dir=log_folder,\n",
    "                         histogram_freq=1,\n",
    "                         write_graph=True,\n",
    "                         write_images=True,\n",
    "                         update_freq='epoch',\n",
    "                         profile_batch=2,\n",
    "                         embeddings_freq=1)\n",
    "\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat, tbcallback]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:08:06.682871221Z",
     "start_time": "2023-10-31T22:08:06.519344596Z"
    }
   },
   "id": "cc5f7688edf0b4ae"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 23:08:08.224969: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-31 23:08:08.346169: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-31 23:08:08.346565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-31 23:08:08.347724: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-31 23:08:08.348812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-31 23:08:08.349074: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-31 23:08:08.349307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-31 23:08:09.494217: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-31 23:08:09.499182: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-31 23:08:09.499649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-31 23:08:09.499900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 348 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 128, 128, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 128, 128, 64  36928       ['block1_conv1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 64, 64, 64)   0           ['block1_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 64, 64, 128)  73856       ['block1_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 64, 64, 128)  147584      ['block2_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 32, 32, 128)  0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 32, 32, 256)  295168      ['block2_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 32, 32, 256)  590080      ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 32, 32, 256)  590080      ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv4 (Conv2D)          (None, 32, 32, 256)  590080      ['block3_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 16, 16, 256)  0           ['block3_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 16, 16, 512)  1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 16, 16, 512)  2359808     ['block4_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 16, 16, 512)  2359808     ['block4_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv4 (Conv2D)          (None, 16, 16, 512)  2359808     ['block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 8, 8, 512)    0           ['block4_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 8, 8, 512)    2359808     ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 8, 8, 512)    2359808     ['block5_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 8, 8, 512)    2359808     ['block5_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv4 (Conv2D)          (None, 8, 8, 512)    2359808     ['block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 1, 1, 512)   0           ['block5_conv4[0][0]']           \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 1, 1, 64)     32832       ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1, 1, 64)    256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 8, 64)     32768       ['block5_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 8, 64)     294912      ['block5_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 8, 8, 64)     294912      ['block5_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 8, 8, 64)     294912      ['block5_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1, 1, 64)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 8, 8, 64)     0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 320)    0           ['up_sampling2d[0][0]',          \n",
      "                                                                  'activation_1[0][0]',           \n",
      "                                                                  'activation_2[0][0]',           \n",
      "                                                                  'activation_3[0][0]',           \n",
      "                                                                  'activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 8, 8, 64)     20480       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 64)  0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 16, 16, 576)  0           ['up_sampling2d_1[0][0]',        \n",
      "                                                                  'block4_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 256)  1327360     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 256)  590080      ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 256)         0           ['activation_7[0][0]']           \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1, 256)    0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 1, 32)     8192        ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1, 256)    8192        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 16, 16, 256)  0           ['activation_7[0][0]',           \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 256)  0          ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 32, 32, 512)  0           ['up_sampling2d_2[0][0]',        \n",
      "                                                                  'block3_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 32, 32, 128)  589952      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 32, 32, 128)  147584      ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 128)         0           ['activation_9[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 1, 128)    0           ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1, 1, 16)     2048        ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1, 1, 128)    2048        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 32, 32, 128)  0           ['activation_9[0][0]',           \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 128)  0          ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 64, 64, 256)  0           ['up_sampling2d_3[0][0]',        \n",
      "                                                                  'block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 64, 64, 64)   147520      ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 64, 64, 64)  256         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 64, 64, 64)   36928       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 64, 64, 64)  256         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 64)          0           ['activation_11[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1, 1, 64)     0           ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1, 1, 8)      512         ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1, 1, 64)     512         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 64, 64, 64)   0           ['activation_11[0][0]',          \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 64  0          ['multiply_2[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 128, 128, 12  0           ['up_sampling2d_4[0][0]',        \n",
      "                                8)                                'block1_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 128, 128, 32  36896       ['concatenate_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 128, 128, 32  128        ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 128, 128, 32  9248        ['activation_12[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 128, 128, 32  128        ['conv2d_13[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 32)          0           ['activation_13[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 1, 1, 32)     0           ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1, 1, 4)      128         ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1, 1, 32)     128         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 128, 128, 32  0           ['activation_13[0][0]',          \n",
      "                                )                                 'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 128, 128, 1)  33          ['multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 128, 128, 1)  0           ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 128, 128, 3)  0           ['input_1[0][0]',                \n",
      "                                                                  'activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 128, 128, 32  896         ['tf.math.multiply[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 128, 128, 32  128        ['conv2d_15[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_14[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 128, 128, 32  9248        ['activation_15[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 128, 128, 32  128        ['conv2d_16[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_15[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4 (Gl  (None, 32)          0           ['activation_16[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 1, 1, 32)     0           ['global_average_pooling2d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1, 1, 4)      128         ['reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1, 1, 32)     128         ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 128, 128, 32  0           ['activation_16[0][0]',          \n",
      "                                )                                 'dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 64, 32)   0           ['multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 64, 64, 64)   18496       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 64, 64, 64)  256         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 64, 64, 64)   36928       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 64, 64, 64)  256         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 64)          0           ['activation_18[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 1, 1, 64)     0           ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1, 1, 8)      512         ['reshape_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1, 1, 64)     512         ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 64, 64, 64)   0           ['activation_18[0][0]',          \n",
      "                                                                  'dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)  0           ['multiply_5[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 32, 32, 128)  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 32, 32, 128)  512        ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 32, 32, 128)  147584      ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 32, 32, 128)  512        ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 128)         0           ['activation_20[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 1, 1, 128)    0           ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 1, 1, 16)     2048        ['reshape_6[0][0]']              \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1, 1, 128)    2048        ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 32, 32, 128)  0           ['activation_20[0][0]',          \n",
      "                                                                  'dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 128)  0          ['multiply_6[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 16, 16, 256)  295168      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 16, 16, 256)  590080      ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7 (Gl  (None, 256)         0           ['activation_22[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 1, 1, 256)    0           ['global_average_pooling2d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 1, 1, 32)     8192        ['reshape_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1, 1, 256)    8192        ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 16, 16, 256)  0           ['activation_22[0][0]',          \n",
      "                                                                  'dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 256)   0           ['multiply_7[0][0]']             \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 1, 1, 256)   0           ['max_pooling2d_3[0][0]']        \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 1, 1, 64)     16448       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 1, 1, 64)    256         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 8, 8, 64)     16384       ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 8, 8, 64)     147456      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 8, 8, 64)     147456      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 8, 8, 64)     147456      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 1, 1, 64)     0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 8, 8, 64)    256         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 8, 8, 64)    256         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 8, 8, 64)    256         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 8, 8, 64)    256         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 8, 8, 64)    0           ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 8, 8, 320)    0           ['up_sampling2d_5[0][0]',        \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]',          \n",
      "                                                                  'activation_26[0][0]',          \n",
      "                                                                  'activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 8, 8, 64)     20480       ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 8, 8, 64)    256         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 16, 16, 64)  0           ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 16, 16, 832)  0           ['up_sampling2d_6[0][0]',        \n",
      "                                                                  'block4_conv4[0][0]',           \n",
      "                                                                  'multiply_7[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 16, 16, 256)  1917184     ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 16, 16, 256)  590080      ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 256)         0           ['activation_30[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)            (None, 1, 1, 256)    0           ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1, 1, 32)     8192        ['reshape_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1, 1, 256)    8192        ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)          (None, 16, 16, 256)  0           ['activation_30[0][0]',          \n",
      "                                                                  'dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 32, 32, 256)  0          ['multiply_8[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 32, 32, 640)  0           ['up_sampling2d_7[0][0]',        \n",
      "                                                                  'block3_conv4[0][0]',           \n",
      "                                                                  'multiply_6[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 32, 32, 128)  737408      ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 32, 32, 128)  512        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 32, 32, 128)  147584      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 32, 32, 128)  512        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_9 (Gl  (None, 128)         0           ['activation_32[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_9 (Reshape)            (None, 1, 1, 128)    0           ['global_average_pooling2d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 1, 1, 16)     2048        ['reshape_9[0][0]']              \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1, 1, 128)    2048        ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_9 (Multiply)          (None, 32, 32, 128)  0           ['activation_32[0][0]',          \n",
      "                                                                  'dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d_8 (UpSampling2D)  (None, 64, 64, 128)  0          ['multiply_9[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 64, 64, 320)  0           ['up_sampling2d_8[0][0]',        \n",
      "                                                                  'block2_conv2[0][0]',           \n",
      "                                                                  'multiply_5[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 64, 64, 64)   184384      ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 64, 64, 64)  256         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 64, 64, 64)   36928       ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 64, 64, 64)  256         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_10 (G  (None, 64)          0           ['activation_34[0][0]']          \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " reshape_10 (Reshape)           (None, 1, 1, 64)     0           ['global_average_pooling2d_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 1, 1, 8)      512         ['reshape_10[0][0]']             \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 1, 1, 64)     512         ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_10 (Multiply)         (None, 64, 64, 64)   0           ['activation_34[0][0]',          \n",
      "                                                                  'dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d_9 (UpSampling2D)  (None, 128, 128, 64  0          ['multiply_10[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 128, 128, 16  0           ['up_sampling2d_9[0][0]',        \n",
      "                                0)                                'block1_conv2[0][0]',           \n",
      "                                                                  'multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 128, 128, 32  46112       ['concatenate_9[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 128, 128, 32  128        ['conv2d_35[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_34[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 128, 128, 32  9248        ['activation_35[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 128, 128, 32  128        ['conv2d_36[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_35[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_11 (G  (None, 32)          0           ['activation_36[0][0]']          \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " reshape_11 (Reshape)           (None, 1, 1, 32)     0           ['global_average_pooling2d_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 1, 1, 4)      128         ['reshape_11[0][0]']             \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 1, 1, 32)     128         ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_11 (Multiply)         (None, 128, 128, 32  0           ['activation_36[0][0]',          \n",
      "                                )                                 'dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 128, 128, 1)  33          ['multiply_11[0][0]']            \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 128, 128, 1)  0           ['conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,297,570\n",
      "Trainable params: 29,290,274\n",
      "Non-trainable params: 7,296\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model =build_model((128,128,3))\n",
    "opt = tf.keras.optimizers.experimental.AdamW(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss= dice_coef_loss,metrics= [dice_coef, precision, iou, sensitivity] ,run_eagerly=True)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:08:13.223474827Z",
     "start_time": "2023-10-31T22:08:08.114371311Z"
    }
   },
   "id": "3e3aeb7279cfc408"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 11336\n",
      "Number of masks: 11336\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74783/2976415279.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  loss_history = model.fit_generator(\n",
      "2023-10-18 02:14:18.724879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8902\n",
      "2023-10-18 02:14:19.413530: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-10-18 02:14:19.416476: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2023-10-18 02:14:19.416561: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:237] Used ptxas at ptxas\n",
      "2023-10-18 02:14:19.416737: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:318] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-10-18 02:14:19.509913: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-18 02:14:19.509950: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-18 02:14:19.640966: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-18 02:14:19.641012: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-18 02:14:19.751424: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-18 02:14:19.751466: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-18 02:14:19.872297: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.18GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-18 02:14:19.872346: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.18GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-18 02:14:19.988250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-18 02:14:20.337115: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-18 02:14:20.337162: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-18 02:14:24.254519: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x852e8a40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-18 02:14:24.254560: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2023-10-18 02:14:24.281530: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-18 02:14:24.463238: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-10-18 02:14:24.466327: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-10-18 02:14:24.594817: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-10-18 02:14:24.709571: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fcff440a040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fcff440a040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 02:14:25.047120: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-10-18 02:14:25.395243: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-10-18 02:14:25.501486: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-10-18 02:14:25.628986: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-10-18 02:14:26.300073: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-10-18 02:14:26.400856: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-10-18 02:14:26.498437: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-10-18 02:14:29.800108: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-10-18 02:14:33.171349: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-10-18 02:14:34.199215: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-10-18 02:14:34.289738: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-10-18 02:14:39.540064: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-10-18 02:14:40.680130: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/1417 [..............................] - ETA: 10:45:09 - loss: 0.8459 - dice_coef: 0.1541 - precision: 0.0893 - iou: 0.0835 - sensitivity: 0.5535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 02:14:44.205537: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2023-10-18 02:14:44.205565: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/1417 [..............................] - ETA: 26:46 - loss: 0.8620 - dice_coef: 0.1380 - precision: 0.0787 - iou: 0.0742 - sensitivity: 0.5526   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 02:14:45.196772: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2023-10-18 02:14:45.223947: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "2023-10-18 02:14:45.300203: I tensorflow/core/profiler/backends/gpu/cupti_collector.cc:522]  GpuTracer has collected 2796 callback api events and 2886 activity events. \n",
      "2023-10-18 02:14:45.321177: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2023-10-18 02:14:45.324368: I tensorflow/core/profiler/rpc/client/save_profile.cc:164] Collecting XSpace to repository: /home/somayeh/PycharmProjects/superpixel_segmentation/tensor_board/plugins/profile/2023_10_18_02_14_45/somayeh-ASUS-TUF-Gaming-F15-FX506HCB-FX506HCB.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1417/1417 [==============================] - ETA: 0s - loss: 0.4815 - dice_coef: 0.5185 - precision: 0.5940 - iou: 0.3673 - sensitivity: 0.8706Number of images: 2834\n",
      "Number of masks: 2834\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.30597, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 611s 412ms/step - loss: 0.4815 - dice_coef: 0.5185 - precision: 0.5940 - iou: 0.3673 - sensitivity: 0.8706 - val_loss: 0.3060 - val_dice_coef: 0.6940 - val_precision: 0.6906 - val_iou: 0.5387 - val_sensitivity: 0.8785 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.1908 - dice_coef: 0.8092 - precision: 0.8593 - iou: 0.6861 - sensitivity: 0.8613\n",
      "Epoch 2: val_loss improved from 0.30597 to 0.14929, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 576s 406ms/step - loss: 0.1908 - dice_coef: 0.8092 - precision: 0.8593 - iou: 0.6861 - sensitivity: 0.8613 - val_loss: 0.1493 - val_dice_coef: 0.8507 - val_precision: 0.9122 - val_iou: 0.7451 - val_sensitivity: 0.8367 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.1363 - dice_coef: 0.8637 - precision: 0.8907 - iou: 0.7655 - sensitivity: 0.8691\n",
      "Epoch 3: val_loss improved from 0.14929 to 0.12650, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 572s 404ms/step - loss: 0.1363 - dice_coef: 0.8637 - precision: 0.8907 - iou: 0.7655 - sensitivity: 0.8691 - val_loss: 0.1265 - val_dice_coef: 0.8735 - val_precision: 0.8940 - val_iou: 0.7798 - val_sensitivity: 0.8709 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.1104 - dice_coef: 0.8896 - precision: 0.9074 - iou: 0.8054 - sensitivity: 0.8874\n",
      "Epoch 4: val_loss improved from 0.12650 to 0.09631, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 574s 405ms/step - loss: 0.1104 - dice_coef: 0.8896 - precision: 0.9074 - iou: 0.8054 - sensitivity: 0.8874 - val_loss: 0.0963 - val_dice_coef: 0.9037 - val_precision: 0.9136 - val_iou: 0.8278 - val_sensitivity: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0951 - dice_coef: 0.9049 - precision: 0.9182 - iou: 0.8294 - sensitivity: 0.9006\n",
      "Epoch 5: val_loss did not improve from 0.09631\n",
      "1417/1417 [==============================] - 574s 405ms/step - loss: 0.0951 - dice_coef: 0.9049 - precision: 0.9182 - iou: 0.8294 - sensitivity: 0.9006 - val_loss: 0.0979 - val_dice_coef: 0.9021 - val_precision: 0.9075 - val_iou: 0.8247 - val_sensitivity: 0.9036 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0909 - dice_coef: 0.9091 - precision: 0.9208 - iou: 0.8370 - sensitivity: 0.9044\n",
      "Epoch 6: val_loss improved from 0.09631 to 0.08681, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 574s 405ms/step - loss: 0.0909 - dice_coef: 0.9091 - precision: 0.9208 - iou: 0.8370 - sensitivity: 0.9044 - val_loss: 0.0868 - val_dice_coef: 0.9132 - val_precision: 0.9308 - val_iou: 0.8428 - val_sensitivity: 0.9011 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0902 - dice_coef: 0.9098 - precision: 0.9204 - iou: 0.8377 - sensitivity: 0.9051\n",
      "Epoch 7: val_loss did not improve from 0.08681\n",
      "1417/1417 [==============================] - 574s 405ms/step - loss: 0.0902 - dice_coef: 0.9098 - precision: 0.9204 - iou: 0.8377 - sensitivity: 0.9051 - val_loss: 0.0952 - val_dice_coef: 0.9048 - val_precision: 0.9178 - val_iou: 0.8303 - val_sensitivity: 0.8981 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0819 - dice_coef: 0.9181 - precision: 0.9289 - iou: 0.8509 - sensitivity: 0.9119\n",
      "Epoch 8: val_loss did not improve from 0.08681\n",
      "1417/1417 [==============================] - 573s 404ms/step - loss: 0.0819 - dice_coef: 0.9181 - precision: 0.9289 - iou: 0.8509 - sensitivity: 0.9119 - val_loss: 0.1115 - val_dice_coef: 0.8885 - val_precision: 0.9147 - val_iou: 0.8047 - val_sensitivity: 0.8704 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0745 - dice_coef: 0.9255 - precision: 0.9331 - iou: 0.8632 - sensitivity: 0.9211\n",
      "Epoch 9: val_loss improved from 0.08681 to 0.07711, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 573s 405ms/step - loss: 0.0745 - dice_coef: 0.9255 - precision: 0.9331 - iou: 0.8632 - sensitivity: 0.9211 - val_loss: 0.0771 - val_dice_coef: 0.9229 - val_precision: 0.9364 - val_iou: 0.8588 - val_sensitivity: 0.9128 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0783 - dice_coef: 0.9217 - precision: 0.9306 - iou: 0.8574 - sensitivity: 0.9172\n",
      "Epoch 10: val_loss improved from 0.07711 to 0.07540, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 573s 404ms/step - loss: 0.0783 - dice_coef: 0.9217 - precision: 0.9306 - iou: 0.8574 - sensitivity: 0.9172 - val_loss: 0.0754 - val_dice_coef: 0.9246 - val_precision: 0.9233 - val_iou: 0.8613 - val_sensitivity: 0.9289 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0749 - dice_coef: 0.9251 - precision: 0.9340 - iou: 0.8628 - sensitivity: 0.9196\n",
      "Epoch 11: val_loss did not improve from 0.07540\n",
      "1417/1417 [==============================] - 573s 405ms/step - loss: 0.0749 - dice_coef: 0.9251 - precision: 0.9340 - iou: 0.8628 - sensitivity: 0.9196 - val_loss: 0.0857 - val_dice_coef: 0.9143 - val_precision: 0.9404 - val_iou: 0.8454 - val_sensitivity: 0.8944 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0690 - dice_coef: 0.9310 - precision: 0.9390 - iou: 0.8723 - sensitivity: 0.9259\n",
      "Epoch 12: val_loss did not improve from 0.07540\n",
      "1417/1417 [==============================] - 574s 405ms/step - loss: 0.0690 - dice_coef: 0.9310 - precision: 0.9390 - iou: 0.8723 - sensitivity: 0.9259 - val_loss: 0.0758 - val_dice_coef: 0.9242 - val_precision: 0.9371 - val_iou: 0.8616 - val_sensitivity: 0.9151 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0633 - dice_coef: 0.9367 - precision: 0.9437 - iou: 0.8819 - sensitivity: 0.9319\n",
      "Epoch 13: val_loss improved from 0.07540 to 0.06788, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 573s 404ms/step - loss: 0.0633 - dice_coef: 0.9367 - precision: 0.9437 - iou: 0.8819 - sensitivity: 0.9319 - val_loss: 0.0679 - val_dice_coef: 0.9321 - val_precision: 0.9443 - val_iou: 0.8740 - val_sensitivity: 0.9224 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0681 - dice_coef: 0.9319 - precision: 0.9401 - iou: 0.8742 - sensitivity: 0.9266\n",
      "Epoch 14: val_loss did not improve from 0.06788\n",
      "1417/1417 [==============================] - 573s 404ms/step - loss: 0.0681 - dice_coef: 0.9319 - precision: 0.9401 - iou: 0.8742 - sensitivity: 0.9266 - val_loss: 0.0913 - val_dice_coef: 0.9087 - val_precision: 0.9239 - val_iou: 0.8368 - val_sensitivity: 0.8997 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0622 - dice_coef: 0.9378 - precision: 0.9442 - iou: 0.8839 - sensitivity: 0.9336\n",
      "Epoch 15: val_loss improved from 0.06788 to 0.06453, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 574s 405ms/step - loss: 0.0622 - dice_coef: 0.9378 - precision: 0.9442 - iou: 0.8839 - sensitivity: 0.9336 - val_loss: 0.0645 - val_dice_coef: 0.9355 - val_precision: 0.9473 - val_iou: 0.8801 - val_sensitivity: 0.9266 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0622 - dice_coef: 0.9378 - precision: 0.9439 - iou: 0.8841 - sensitivity: 0.9341\n",
      "Epoch 16: val_loss did not improve from 0.06453\n",
      "1417/1417 [==============================] - 574s 405ms/step - loss: 0.0622 - dice_coef: 0.9378 - precision: 0.9439 - iou: 0.8841 - sensitivity: 0.9341 - val_loss: 0.0684 - val_dice_coef: 0.9316 - val_precision: 0.9483 - val_iou: 0.8744 - val_sensitivity: 0.9189 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0594 - dice_coef: 0.9406 - precision: 0.9467 - iou: 0.8888 - sensitivity: 0.9364\n",
      "Epoch 17: val_loss did not improve from 0.06453\n",
      "1417/1417 [==============================] - 575s 406ms/step - loss: 0.0594 - dice_coef: 0.9406 - precision: 0.9467 - iou: 0.8888 - sensitivity: 0.9364 - val_loss: 0.0764 - val_dice_coef: 0.9236 - val_precision: 0.9240 - val_iou: 0.8599 - val_sensitivity: 0.9264 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0605 - dice_coef: 0.9395 - precision: 0.9450 - iou: 0.8873 - sensitivity: 0.9360\n",
      "Epoch 18: val_loss improved from 0.06453 to 0.06126, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 574s 405ms/step - loss: 0.0605 - dice_coef: 0.9395 - precision: 0.9450 - iou: 0.8873 - sensitivity: 0.9360 - val_loss: 0.0613 - val_dice_coef: 0.9387 - val_precision: 0.9494 - val_iou: 0.8858 - val_sensitivity: 0.9304 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0545 - dice_coef: 0.9455 - precision: 0.9511 - iou: 0.8977 - sensitivity: 0.9417\n",
      "Epoch 19: val_loss did not improve from 0.06126\n",
      "1417/1417 [==============================] - 576s 406ms/step - loss: 0.0545 - dice_coef: 0.9455 - precision: 0.9511 - iou: 0.8977 - sensitivity: 0.9417 - val_loss: 0.0882 - val_dice_coef: 0.9118 - val_precision: 0.9197 - val_iou: 0.8412 - val_sensitivity: 0.9085 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0562 - dice_coef: 0.9438 - precision: 0.9492 - iou: 0.8944 - sensitivity: 0.9401\n",
      "Epoch 20: val_loss improved from 0.06126 to 0.05918, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 577s 407ms/step - loss: 0.0562 - dice_coef: 0.9438 - precision: 0.9492 - iou: 0.8944 - sensitivity: 0.9401 - val_loss: 0.0592 - val_dice_coef: 0.9408 - val_precision: 0.9532 - val_iou: 0.8894 - val_sensitivity: 0.9306 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0601 - dice_coef: 0.9399 - precision: 0.9459 - iou: 0.8878 - sensitivity: 0.9362\n",
      "Epoch 21: val_loss did not improve from 0.05918\n",
      "1417/1417 [==============================] - 575s 406ms/step - loss: 0.0601 - dice_coef: 0.9399 - precision: 0.9459 - iou: 0.8878 - sensitivity: 0.9362 - val_loss: 0.0736 - val_dice_coef: 0.9264 - val_precision: 0.9308 - val_iou: 0.8652 - val_sensitivity: 0.9254 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0519 - dice_coef: 0.9481 - precision: 0.9531 - iou: 0.9018 - sensitivity: 0.9445\n",
      "Epoch 22: val_loss did not improve from 0.05918\n",
      "1417/1417 [==============================] - 576s 406ms/step - loss: 0.0519 - dice_coef: 0.9481 - precision: 0.9531 - iou: 0.9018 - sensitivity: 0.9445 - val_loss: 0.0627 - val_dice_coef: 0.9373 - val_precision: 0.9390 - val_iou: 0.8832 - val_sensitivity: 0.9378 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0522 - dice_coef: 0.9478 - precision: 0.9526 - iou: 0.9016 - sensitivity: 0.9446\n",
      "Epoch 23: val_loss did not improve from 0.05918\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "1417/1417 [==============================] - 576s 406ms/step - loss: 0.0522 - dice_coef: 0.9478 - precision: 0.9526 - iou: 0.9016 - sensitivity: 0.9446 - val_loss: 0.1009 - val_dice_coef: 0.8991 - val_precision: 0.9222 - val_iou: 0.8205 - val_sensitivity: 0.8819 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0494 - dice_coef: 0.9506 - precision: 0.9550 - iou: 0.9063 - sensitivity: 0.9474\n",
      "Epoch 24: val_loss improved from 0.05918 to 0.05304, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 577s 407ms/step - loss: 0.0494 - dice_coef: 0.9506 - precision: 0.9550 - iou: 0.9063 - sensitivity: 0.9474 - val_loss: 0.0530 - val_dice_coef: 0.9470 - val_precision: 0.9517 - val_iou: 0.8999 - val_sensitivity: 0.9436 - lr: 5.0000e-05\n",
      "Epoch 25/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0449 - dice_coef: 0.9551 - precision: 0.9590 - iou: 0.9143 - sensitivity: 0.9523\n",
      "Epoch 25: val_loss improved from 0.05304 to 0.05296, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 577s 407ms/step - loss: 0.0449 - dice_coef: 0.9551 - precision: 0.9590 - iou: 0.9143 - sensitivity: 0.9523 - val_loss: 0.0530 - val_dice_coef: 0.9470 - val_precision: 0.9532 - val_iou: 0.9000 - val_sensitivity: 0.9424 - lr: 5.0000e-05\n",
      "Epoch 26/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0444 - dice_coef: 0.9556 - precision: 0.9595 - iou: 0.9153 - sensitivity: 0.9529\n",
      "Epoch 26: val_loss improved from 0.05296 to 0.05270, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 583s 412ms/step - loss: 0.0444 - dice_coef: 0.9556 - precision: 0.9595 - iou: 0.9153 - sensitivity: 0.9529 - val_loss: 0.0527 - val_dice_coef: 0.9473 - val_precision: 0.9557 - val_iou: 0.9005 - val_sensitivity: 0.9405 - lr: 5.0000e-05\n",
      "Epoch 27/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0429 - dice_coef: 0.9571 - precision: 0.9607 - iou: 0.9179 - sensitivity: 0.9545\n",
      "Epoch 27: val_loss did not improve from 0.05270\n",
      "1417/1417 [==============================] - 587s 414ms/step - loss: 0.0429 - dice_coef: 0.9571 - precision: 0.9607 - iou: 0.9179 - sensitivity: 0.9545 - val_loss: 0.0528 - val_dice_coef: 0.9472 - val_precision: 0.9539 - val_iou: 0.9006 - val_sensitivity: 0.9422 - lr: 5.0000e-05\n",
      "Epoch 28/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0431 - dice_coef: 0.9569 - precision: 0.9606 - iou: 0.9176 - sensitivity: 0.9543\n",
      "Epoch 28: val_loss improved from 0.05270 to 0.05139, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 582s 411ms/step - loss: 0.0431 - dice_coef: 0.9569 - precision: 0.9606 - iou: 0.9176 - sensitivity: 0.9543 - val_loss: 0.0514 - val_dice_coef: 0.9486 - val_precision: 0.9541 - val_iou: 0.9028 - val_sensitivity: 0.9446 - lr: 5.0000e-05\n",
      "Epoch 29/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0415 - dice_coef: 0.9585 - precision: 0.9619 - iou: 0.9206 - sensitivity: 0.9562\n",
      "Epoch 29: val_loss improved from 0.05139 to 0.05004, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 582s 411ms/step - loss: 0.0415 - dice_coef: 0.9585 - precision: 0.9619 - iou: 0.9206 - sensitivity: 0.9562 - val_loss: 0.0500 - val_dice_coef: 0.9500 - val_precision: 0.9563 - val_iou: 0.9052 - val_sensitivity: 0.9451 - lr: 5.0000e-05\n",
      "Epoch 30/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0407 - dice_coef: 0.9593 - precision: 0.9627 - iou: 0.9219 - sensitivity: 0.9569\n",
      "Epoch 30: val_loss did not improve from 0.05004\n",
      "1417/1417 [==============================] - 584s 412ms/step - loss: 0.0407 - dice_coef: 0.9593 - precision: 0.9627 - iou: 0.9219 - sensitivity: 0.9569 - val_loss: 0.0510 - val_dice_coef: 0.9490 - val_precision: 0.9567 - val_iou: 0.9037 - val_sensitivity: 0.9428 - lr: 5.0000e-05\n",
      "Epoch 31/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0399 - dice_coef: 0.9601 - precision: 0.9635 - iou: 0.9235 - sensitivity: 0.9578\n",
      "Epoch 31: val_loss improved from 0.05004 to 0.04983, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 583s 411ms/step - loss: 0.0399 - dice_coef: 0.9601 - precision: 0.9635 - iou: 0.9235 - sensitivity: 0.9578 - val_loss: 0.0498 - val_dice_coef: 0.9502 - val_precision: 0.9503 - val_iou: 0.9056 - val_sensitivity: 0.9514 - lr: 5.0000e-05\n",
      "Epoch 32/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0398 - dice_coef: 0.9602 - precision: 0.9635 - iou: 0.9237 - sensitivity: 0.9581\n",
      "Epoch 32: val_loss improved from 0.04983 to 0.04978, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 583s 411ms/step - loss: 0.0398 - dice_coef: 0.9602 - precision: 0.9635 - iou: 0.9237 - sensitivity: 0.9581 - val_loss: 0.0498 - val_dice_coef: 0.9502 - val_precision: 0.9548 - val_iou: 0.9057 - val_sensitivity: 0.9470 - lr: 5.0000e-05\n",
      "Epoch 33/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0381 - dice_coef: 0.9619 - precision: 0.9652 - iou: 0.9267 - sensitivity: 0.9596\n",
      "Epoch 33: val_loss improved from 0.04978 to 0.04836, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 585s 413ms/step - loss: 0.0381 - dice_coef: 0.9619 - precision: 0.9652 - iou: 0.9267 - sensitivity: 0.9596 - val_loss: 0.0484 - val_dice_coef: 0.9516 - val_precision: 0.9560 - val_iou: 0.9083 - val_sensitivity: 0.9486 - lr: 5.0000e-05\n",
      "Epoch 34/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0391 - dice_coef: 0.9609 - precision: 0.9641 - iou: 0.9250 - sensitivity: 0.9588\n",
      "Epoch 34: val_loss did not improve from 0.04836\n",
      "1417/1417 [==============================] - 586s 413ms/step - loss: 0.0391 - dice_coef: 0.9609 - precision: 0.9641 - iou: 0.9250 - sensitivity: 0.9588 - val_loss: 0.0512 - val_dice_coef: 0.9488 - val_precision: 0.9523 - val_iou: 0.9034 - val_sensitivity: 0.9470 - lr: 5.0000e-05\n",
      "Epoch 35/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0374 - dice_coef: 0.9626 - precision: 0.9657 - iou: 0.9282 - sensitivity: 0.9606\n",
      "Epoch 35: val_loss did not improve from 0.04836\n",
      "1417/1417 [==============================] - 584s 412ms/step - loss: 0.0374 - dice_coef: 0.9626 - precision: 0.9657 - iou: 0.9282 - sensitivity: 0.9606 - val_loss: 0.0504 - val_dice_coef: 0.9496 - val_precision: 0.9517 - val_iou: 0.9047 - val_sensitivity: 0.9490 - lr: 5.0000e-05\n",
      "Epoch 36/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0366 - dice_coef: 0.9634 - precision: 0.9664 - iou: 0.9295 - sensitivity: 0.9614\n",
      "Epoch 36: val_loss improved from 0.04836 to 0.04801, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 586s 413ms/step - loss: 0.0366 - dice_coef: 0.9634 - precision: 0.9664 - iou: 0.9295 - sensitivity: 0.9614 - val_loss: 0.0480 - val_dice_coef: 0.9520 - val_precision: 0.9578 - val_iou: 0.9090 - val_sensitivity: 0.9476 - lr: 5.0000e-05\n",
      "Epoch 37/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0361 - dice_coef: 0.9639 - precision: 0.9669 - iou: 0.9305 - sensitivity: 0.9620\n",
      "Epoch 37: val_loss improved from 0.04801 to 0.04796, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 585s 413ms/step - loss: 0.0361 - dice_coef: 0.9639 - precision: 0.9669 - iou: 0.9305 - sensitivity: 0.9620 - val_loss: 0.0480 - val_dice_coef: 0.9520 - val_precision: 0.9560 - val_iou: 0.9093 - val_sensitivity: 0.9496 - lr: 5.0000e-05\n",
      "Epoch 38/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0355 - dice_coef: 0.9645 - precision: 0.9675 - iou: 0.9315 - sensitivity: 0.9625\n",
      "Epoch 38: val_loss improved from 0.04796 to 0.04739, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 585s 413ms/step - loss: 0.0355 - dice_coef: 0.9645 - precision: 0.9675 - iou: 0.9315 - sensitivity: 0.9625 - val_loss: 0.0474 - val_dice_coef: 0.9526 - val_precision: 0.9544 - val_iou: 0.9101 - val_sensitivity: 0.9522 - lr: 5.0000e-05\n",
      "Epoch 39/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0349 - dice_coef: 0.9651 - precision: 0.9678 - iou: 0.9327 - sensitivity: 0.9634\n",
      "Epoch 39: val_loss improved from 0.04739 to 0.04688, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 587s 414ms/step - loss: 0.0349 - dice_coef: 0.9651 - precision: 0.9678 - iou: 0.9327 - sensitivity: 0.9634 - val_loss: 0.0469 - val_dice_coef: 0.9531 - val_precision: 0.9574 - val_iou: 0.9111 - val_sensitivity: 0.9503 - lr: 5.0000e-05\n",
      "Epoch 40/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0347 - dice_coef: 0.9653 - precision: 0.9681 - iou: 0.9331 - sensitivity: 0.9635\n",
      "Epoch 40: val_loss improved from 0.04688 to 0.04650, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 587s 414ms/step - loss: 0.0347 - dice_coef: 0.9653 - precision: 0.9681 - iou: 0.9331 - sensitivity: 0.9635 - val_loss: 0.0465 - val_dice_coef: 0.9535 - val_precision: 0.9575 - val_iou: 0.9117 - val_sensitivity: 0.9509 - lr: 5.0000e-05\n",
      "Epoch 41/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0340 - dice_coef: 0.9660 - precision: 0.9687 - iou: 0.9344 - sensitivity: 0.9643\n",
      "Epoch 41: val_loss improved from 0.04650 to 0.04643, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 587s 414ms/step - loss: 0.0340 - dice_coef: 0.9660 - precision: 0.9687 - iou: 0.9344 - sensitivity: 0.9643 - val_loss: 0.0464 - val_dice_coef: 0.9536 - val_precision: 0.9583 - val_iou: 0.9118 - val_sensitivity: 0.9503 - lr: 5.0000e-05\n",
      "Epoch 42/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0334 - dice_coef: 0.9666 - precision: 0.9692 - iou: 0.9354 - sensitivity: 0.9650\n",
      "Epoch 42: val_loss improved from 0.04643 to 0.04592, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 589s 415ms/step - loss: 0.0334 - dice_coef: 0.9666 - precision: 0.9692 - iou: 0.9354 - sensitivity: 0.9650 - val_loss: 0.0459 - val_dice_coef: 0.9541 - val_precision: 0.9544 - val_iou: 0.9127 - val_sensitivity: 0.9550 - lr: 5.0000e-05\n",
      "Epoch 43/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0330 - dice_coef: 0.9670 - precision: 0.9697 - iou: 0.9363 - sensitivity: 0.9654\n",
      "Epoch 43: val_loss did not improve from 0.04592\n",
      "1417/1417 [==============================] - 588s 415ms/step - loss: 0.0330 - dice_coef: 0.9670 - precision: 0.9697 - iou: 0.9363 - sensitivity: 0.9654 - val_loss: 0.0470 - val_dice_coef: 0.9530 - val_precision: 0.9569 - val_iou: 0.9111 - val_sensitivity: 0.9507 - lr: 5.0000e-05\n",
      "Epoch 44/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0329 - dice_coef: 0.9671 - precision: 0.9698 - iou: 0.9365 - sensitivity: 0.9655\n",
      "Epoch 44: val_loss improved from 0.04592 to 0.04564, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 588s 415ms/step - loss: 0.0329 - dice_coef: 0.9671 - precision: 0.9698 - iou: 0.9365 - sensitivity: 0.9655 - val_loss: 0.0456 - val_dice_coef: 0.9544 - val_precision: 0.9576 - val_iou: 0.9132 - val_sensitivity: 0.9525 - lr: 5.0000e-05\n",
      "Epoch 45/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0320 - dice_coef: 0.9680 - precision: 0.9706 - iou: 0.9381 - sensitivity: 0.9663\n",
      "Epoch 45: val_loss improved from 0.04564 to 0.04534, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 590s 416ms/step - loss: 0.0320 - dice_coef: 0.9680 - precision: 0.9706 - iou: 0.9381 - sensitivity: 0.9663 - val_loss: 0.0453 - val_dice_coef: 0.9547 - val_precision: 0.9574 - val_iou: 0.9139 - val_sensitivity: 0.9533 - lr: 5.0000e-05\n",
      "Epoch 46/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0315 - dice_coef: 0.9685 - precision: 0.9709 - iou: 0.9390 - sensitivity: 0.9671\n",
      "Epoch 46: val_loss did not improve from 0.04534\n",
      "1417/1417 [==============================] - 590s 416ms/step - loss: 0.0315 - dice_coef: 0.9685 - precision: 0.9709 - iou: 0.9390 - sensitivity: 0.9671 - val_loss: 0.0455 - val_dice_coef: 0.9545 - val_precision: 0.9590 - val_iou: 0.9135 - val_sensitivity: 0.9514 - lr: 5.0000e-05\n",
      "Epoch 47/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0312 - dice_coef: 0.9688 - precision: 0.9714 - iou: 0.9396 - sensitivity: 0.9672\n",
      "Epoch 47: val_loss improved from 0.04534 to 0.04490, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 589s 416ms/step - loss: 0.0312 - dice_coef: 0.9688 - precision: 0.9714 - iou: 0.9396 - sensitivity: 0.9672 - val_loss: 0.0449 - val_dice_coef: 0.9551 - val_precision: 0.9583 - val_iou: 0.9145 - val_sensitivity: 0.9532 - lr: 5.0000e-05\n",
      "Epoch 48/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0321 - dice_coef: 0.9679 - precision: 0.9705 - iou: 0.9380 - sensitivity: 0.9664\n",
      "Epoch 48: val_loss improved from 0.04490 to 0.04423, saving model to cxr_reg_Dunet_superpixel_extended_cvc_slic800.best.hdf5\n",
      "1417/1417 [==============================] - 590s 416ms/step - loss: 0.0321 - dice_coef: 0.9679 - precision: 0.9705 - iou: 0.9380 - sensitivity: 0.9664 - val_loss: 0.0442 - val_dice_coef: 0.9558 - val_precision: 0.9589 - val_iou: 0.9158 - val_sensitivity: 0.9540 - lr: 5.0000e-05\n",
      "Epoch 49/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0302 - dice_coef: 0.9698 - precision: 0.9721 - iou: 0.9416 - sensitivity: 0.9686\n",
      "Epoch 49: val_loss did not improve from 0.04423\n",
      "1417/1417 [==============================] - 589s 416ms/step - loss: 0.0302 - dice_coef: 0.9698 - precision: 0.9721 - iou: 0.9416 - sensitivity: 0.9686 - val_loss: 0.0448 - val_dice_coef: 0.9552 - val_precision: 0.9601 - val_iou: 0.9149 - val_sensitivity: 0.9519 - lr: 5.0000e-05\n",
      "Epoch 50/50\n",
      "1417/1417 [==============================] - ETA: 0s - loss: 0.0298 - dice_coef: 0.9702 - precision: 0.9726 - iou: 0.9422 - sensitivity: 0.9688\n",
      "Epoch 50: val_loss did not improve from 0.04423\n",
      "1417/1417 [==============================] - 591s 417ms/step - loss: 0.0298 - dice_coef: 0.9702 - precision: 0.9726 - iou: 0.9422 - sensitivity: 0.9688 - val_loss: 0.0447 - val_dice_coef: 0.9553 - val_precision: 0.9602 - val_iou: 0.9150 - val_sensitivity: 0.9517 - lr: 5.0000e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_steps_per_epoch,\n",
    "    epochs=50,\n",
    "    callbacks =callbacks_list\n",
    ")\n",
    "\n",
    "model.save(\"Dunet_superpixel_extended_cvc_slic800.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T08:18:32.539134948Z",
     "start_time": "2023-10-18T00:14:16.690493697Z"
    }
   },
   "id": "28bcf5e913c6fa82"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "test_paths = glob.glob(\"/home/somayeh/PycharmProjects/superpixel_segmentation/new_data/test_all/image/*.jpg\")\n",
    "test_mask_paths = glob.glob(\"/home/somayeh/PycharmProjects/superpixel_segmentation/new_data/test_all/mask/*.jpg\")\n",
    "\n",
    "# test_paths = glob.glob(\"/home/somayeh/PycharmProjects/superpixel_segmentation/PolypDataset/TestDataset/TestDataset/ETIS-LaribPolypDB/images/*.png\")\n",
    "# test_mask_paths= glob.glob(\"/home/somayeh/PycharmProjects/superpixel_segmentation/PolypDataset/TestDataset/TestDataset/ETIS-LaribPolypDB/masks/*.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:08:58.373495087Z",
     "start_time": "2023-10-31T22:08:58.328407176Z"
    }
   },
   "id": "188419b7c713b71a"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 128, 128, 3)\n",
      "(35, 128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 23:09:58.532410: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-10-31 23:09:58.532491: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops.cc:1152 : UNIMPLEMENTED: DNN library is not found.\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Exception encountered when calling layer 'block1_conv1' (type Conv2D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} DNN library is not found. [Op:Conv2D]\n\nCall arguments received by layer 'block1_conv1' (type Conv2D):\n  • inputs=tf.Tensor(shape=(1, 128, 128, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnimplementedError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 44\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m# model_weights = model.get_weights()\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# # Print the weights\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# for layer_weights in model_weights:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Make predictions\u001B[39;00m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m# predicted_masks = model.predict(test_images)\u001B[39;00m\n\u001B[1;32m     43\u001B[0m tf\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mrun_functions_eagerly(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 44\u001B[0m predicted_masks \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtest_images\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[1;32m     50\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m predicted_mask_array \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(predicted_masks)\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28mprint\u001B[39m(predicted_mask_array\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[0;32m~/PycharmProjects/superpixel_segmentation/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/PycharmProjects/superpixel_segmentation/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7215\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   7213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name):\n\u001B[1;32m   7214\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 7215\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
      "\u001B[0;31mUnimplementedError\u001B[0m: Exception encountered when calling layer 'block1_conv1' (type Conv2D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} DNN library is not found. [Op:Conv2D]\n\nCall arguments received by layer 'block1_conv1' (type Conv2D):\n  • inputs=tf.Tensor(shape=(1, 128, 128, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "dice_scores = []\n",
    "test_images = []\n",
    "ground_truth_test_images = []\n",
    "for test_path, test_mask_path in zip(test_paths, test_mask_paths):\n",
    "    # read the image and mask using OpenCV\n",
    "    test_image = cv2.imread(test_path)\n",
    "    ground_truth_test_image = cv2.imread(test_mask_path, 0)  # read the mask as grayscale\n",
    "\n",
    "    # resize the image and mask to the desired dimensions\n",
    "    test_image = cv2.resize(test_image, (128, 128))\n",
    "    ground_truth_test_image = cv2.resize(ground_truth_test_image, (128, 128))\n",
    "\n",
    "# normalize the image and mask to have values between 0 and 1\n",
    "\n",
    "    test_image = test_image / 255.0\n",
    "    ground_truth_test_image= ground_truth_test_image / 255.0\n",
    "\n",
    "    # add the image and mask to the corresponding arrays\n",
    "    test_images.append(test_image)\n",
    "    ground_truth_test_images.append(ground_truth_test_image)\n",
    "\n",
    "\n",
    "#by the end of this line, I have superpixeled images.\n",
    "# convert the images and masks to numpy arrays\n",
    "test_images = np.array(test_images)\n",
    "ground_truth_test_images = np.array(ground_truth_test_images)\n",
    "print(test_images.shape)\n",
    "print(ground_truth_test_images.shape)\n",
    "# add a channel dimension to the masks\n",
    "# ground_truth_test_images = np.expand_dims(ground_truth_test_images, axis=-1)\n",
    "\n",
    "# model = load_model('unet_super_pixel_extended_cvc_slic800.h5')\n",
    "weight_path=\"{}_Dunet_superpixel_extended_cvc_slic800.best.hdf5\".format('cxr_reg')\n",
    "\n",
    "# model_weights = model.get_weights()\n",
    "# # Print the weights\n",
    "# for layer_weights in model_weights:\n",
    "#     print(layer_weights)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "# predicted_masks = model.predict(test_images)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "predicted_masks = model.predict(\n",
    "    test_images,\n",
    "    batch_size=1,\n",
    "    verbose=1,\n",
    "    steps=None,\n",
    "    callbacks=None\n",
    ")\n",
    "\n",
    "predicted_mask_array = np.array(predicted_masks)\n",
    "print(predicted_mask_array.shape)\n",
    "\n",
    "# Convert the NumPy array to uint8 format\n",
    "predicted_mask_array = (predicted_mask_array * 255).astype(np.uint8)\n",
    "print(predicted_mask_array.shape)\n",
    "\n",
    "\n",
    "dst = np.empty([predicted_mask_array.shape[0],predicted_mask_array.shape[1],predicted_mask_array.shape[2]])\n",
    "kernel = np.ones((5,5),np.float64)/25\n",
    "# dst = predicted_mask_array\n",
    "\n",
    "#\n",
    "for i in range(predicted_mask_array.shape[0]):\n",
    "\n",
    "        threshold_value = 1\n",
    "        _, dst[i] = cv2.threshold(predicted_mask_array[i], threshold_value, 255, cv2.THRESH_BINARY)\n",
    "        dst[i] = np.array(dst[i])\n",
    "        dst[i] = tf.convert_to_tensor(dst[i] / 255.0,dtype=predicted_masks.dtype)\n",
    "\n",
    "print(dst.shape)\n",
    "\n",
    "## Cast the input tensor to a double tensor\n",
    "ground_truth_test_images = tf.cast(ground_truth_test_images, dtype=tf.float64)\n",
    "predicted_masks = tf.cast(dst, dtype=tf.float64)\n",
    "# predicted_masks = tf.cast(predicted_mask_array, dtype=tf.float64)\n",
    "# Apply thresholding\n",
    "\n",
    "dice_scores = []  # List to store the dice coefficients\n",
    "precision_scores = []\n",
    "sensitivity_scores = []\n",
    "iou_scores = []\n",
    "\n",
    "# Iterate over the images and calculate the dice coefficient\n",
    "for i in range(len(ground_truth_test_images)):\n",
    "    y_true = ground_truth_test_images[i]\n",
    "    y_pred = predicted_masks[i]\n",
    "\n",
    "    dice = dice_coef(y_true, y_pred)\n",
    "    dice_scores.append(dice)\n",
    "\n",
    "# Compute the average dice coefficient\n",
    "average_dice = np.mean(dice_scores)\n",
    "\n",
    "for i in range(len(ground_truth_test_images)):\n",
    "    y_true = ground_truth_test_images[i]\n",
    "    dice = dice_coef(y_true, y_pred)\n",
    "\n",
    "    y_pred = predicted_masks[i]\n",
    "\n",
    "    precision_value = precision(y_true, y_pred)\n",
    "    precision_scores.append(precision_value)\n",
    "\n",
    "# Compute the average dice coefficient\n",
    "average_precision = np.mean(precision_scores)\n",
    "\n",
    "for i in range(len(ground_truth_test_images)):\n",
    "    y_true = ground_truth_test_images[i]\n",
    "    y_pred = predicted_masks[i]\n",
    "\n",
    "    sensitivity_value = sensitivity(y_true, y_pred)\n",
    "    sensitivity_scores.append(sensitivity_value)\n",
    "\n",
    "# Compute the average dice coefficient\n",
    "average_sensitivity = np.mean(sensitivity_scores)\n",
    "\n",
    "for i in range(len(ground_truth_test_images)):\n",
    "    y_true = ground_truth_test_images[i]\n",
    "    y_pred = predicted_masks[i]\n",
    "\n",
    "    iou_value = iou(y_true, y_pred)\n",
    "    iou_scores.append(iou_value)\n",
    "\n",
    "# Compute the average dice coefficient\n",
    "average_iou = np.mean(iou_scores)\n",
    "\n",
    "# dice_score = dice_coef(ground_truth_test_images, dst)\n",
    "# precision_val = precision(ground_truth_test_images, dst)\n",
    "# sensitivity_val = sensitivity(ground_truth_test_images, dst)\n",
    "# iou_val = iou(ground_truth_test_images, dst)\n",
    "# print(type(dst))\n",
    "\n",
    "print(\"Dices:\", dice_scores)\n",
    "print(\"Dice coefficient:\", average_dice)\n",
    "print(\"Precision:\", average_precision)\n",
    "print(\"Sensitivity:\", average_sensitivity)\n",
    "print(\"IoU:\", average_iou)\n",
    "\n",
    "n =35 # number of images to show\n",
    "for i in range(n):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    ax[0].imshow(test_images[i])\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[1].imshow(ground_truth_test_images[i])\n",
    "    ax[1].set_title('Original Mask')\n",
    "    ax[2].imshow(dst[i])\n",
    "    ax[2].set_title('Predicted Mask')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:09:58.630204992Z",
     "start_time": "2023-10-31T22:09:58.361059047Z"
    }
   },
   "id": "dadcf514e8b14131"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c54dc7f2516833d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
